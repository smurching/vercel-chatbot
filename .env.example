# ============================================
# REQUIRED: Databricks Configuration
# ============================================
# TODO: set DATABRICKS_CONFIG_PROFILE
# First, run databricks auth login [--profile name]
# Then, set the profile name here (if you didn't specify a profile name, use "DEFAULT" as the profile name)
DATABRICKS_CONFIG_PROFILE=your-profile-name

# ============================================
# REQUIRED: PostgreSQL Configuration
# ============================================
# Option 1: Use individual PG* variables (recommended)
#
# This setup mimics the final setup when you deploy to Databricks apps,
# resulting in a higher-fidelity local dev environment
#
# Given the name of a lakebase instance, you can find the values below via the Databricks CLI, e.g
# by running `databricks database get-database-instance "chatbot-lakebase-dev" | jq .read_write_dns`.
#
# TODO: set PGUSER
# This should be your Databricks username, i.e. the output of
# running `databricks auth describe --output json | jq .username`
PGUSER=your-databricks-username
# TODO: set PGHOST.
# Given your database instance name, you can get the value of PGHOST from the read_write_dns
# metadata field on your instance, e.g by running
# `databricks database get-database-instance "chatbot-lakebase-dev" | jq .read_write_dns`
PGHOST=your-postgres-host

# The following environment variables have the following default values on Databricks,
# so you probably don't need to change them:
PGDATABASE=databricks_postgres
PGPORT=5432

# Option 2: Use full connection string (alternative to PG* variables)
# POSTGRES_URL=postgresql://username:password@host:port/database
