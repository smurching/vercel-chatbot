# ============================================
# REQUIRED: Databricks Configuration
# ============================================
# Option 1: CLI OAuth U2M (recommended for individual users)
# First run: databricks auth login
# Optional: specify a profile name (uses default if not set)
DATABRICKS_CONFIG_PROFILE=your-profile-name

# Or alternatively, specify host directly for CLI auth:
# DATABRICKS_HOST=your-workspace.cloud.databricks.com

# Option 2: OAuth application credentials (recommended for production)
# Create a service principal and OAuth app in your Databricks workspace
# DATABRICKS_HOST=your-workspace.cloud.databricks.com
# DATABRICKS_CLIENT_ID=your-oauth-client-id
# DATABRICKS_CLIENT_SECRET=your-oauth-client-secret

# ============================================
# REQUIRED: PostgreSQL Configuration
# ============================================
# Option 1: Use individual PG* variables (recommended for Databricks authentication)
PGHOST=your-postgres-host
PGDATABASE=your-database-name
PGUSER=your-username
PGPORT=5432
# Note: PGPASSWORD is automatically set via Databricks token exchange

# Option 2: Use full connection string (alternative to PG* variables)
# POSTGRES_URL=postgresql://username:password@host:port/database

# ============================================
# OPTIONAL: Additional Services
# ============================================
# AI Gateway API Key (required for non-Vercel deployments)
# For Vercel deployments, OIDC tokens are used automatically
AI_GATEWAY_API_KEY=****

# Blob storage for file uploads (optional)
BLOB_READ_WRITE_TOKEN=****

# Redis for resumable streams (optional)
REDIS_URL=****
